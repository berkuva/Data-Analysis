{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates using machine learning for detecting malicious software based on the system calls the software uses. It is done as a project for CS6456-Fall 2019 at The University of Virginia. Further details can be found here: http://www.cs.virginia.edu/~bjc8c/class/cs6456-f19/hw4.html. \n",
    "\n",
    "Below uses a simple three-layered (2 hidden, 1 output) neural network implemented in PyTorch.\n",
    "Author: Hyun Jae Cho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_91</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "      <th>malware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22398</th>\n",
       "      <td>437ea215f277aa8f26cfc3d78293bc9c</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26055</th>\n",
       "      <td>998c71564f5422d46cb4922e7d95e945</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21552</th>\n",
       "      <td>096cddfffe60c02156959691e187b0f2</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18102</th>\n",
       "      <td>216c9495d94be7ee47e09dad98f9aa68</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>178</td>\n",
       "      <td>215</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20284</th>\n",
       "      <td>e9c2d6c78943ee4002c5fcab2c6df21c</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>159</td>\n",
       "      <td>224</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   hash  t_0  t_1  t_2  t_3  t_4  t_5  t_6  \\\n",
       "22398  437ea215f277aa8f26cfc3d78293bc9c  240  117  240  117  240  117  240   \n",
       "26055  998c71564f5422d46cb4922e7d95e945   82  240  117  240  117  240  117   \n",
       "21552  096cddfffe60c02156959691e187b0f2   82  240  117  240  117  240  117   \n",
       "18102  216c9495d94be7ee47e09dad98f9aa68   82   86   82   37   70   37  240   \n",
       "20284  e9c2d6c78943ee4002c5fcab2c6df21c   82  240  117  240  117  240  117   \n",
       "\n",
       "       t_7  t_8   ...     t_91  t_92  t_93  t_94  t_95  t_96  t_97  t_98  \\\n",
       "22398  117  240   ...       15   240   117   240   117   240   117   172   \n",
       "26055  240  117   ...      215    60    81    60    81    60    81   208   \n",
       "21552  240  117   ...      260   141   260   141   260   141   260   141   \n",
       "18102  117  260   ...      215   178   215   260    65   260   141    65   \n",
       "20284  240  117   ...      224    82   208   159   224    82   240   117   \n",
       "\n",
       "       t_99  malware  \n",
       "22398    60        1  \n",
       "26055   187        1  \n",
       "21552   260        1  \n",
       "18102    20        1  \n",
       "20284   159        1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"api_calls.csv\", error_bad_lines=False)\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train 70%, validation 10%, and test 20%\n",
    "\n",
    "X = df.drop([\"malware\"], axis=1)\n",
    "y = df['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                  y_test,\n",
    "                                                  test_size=0.66,\n",
    "                                                  random_state=1)\n",
    "\n",
    "X_train, X_val = X_train.drop([\"hash\"], axis=1), X_val.drop([\"hash\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data (70%)\n",
      "(30713, 100) (30713,)\n",
      "\n",
      "Size of validation data (10%)\n",
      "(4475, 100) (4475,)\n",
      "\n",
      "Size of test data (20%)\n",
      "(8688, 101) (8688,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train data (70%)\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(\"\\nSize of validation data (10%)\")\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(\"\\nSize of test data (20%)\")\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, dataset, labels):\n",
    "        self.labels = labels\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = torch.tensor(np.int64(self.dataset.iloc[index]))\n",
    "        y = self.labels.iloc[index]\n",
    "        return X, y\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, dataset, labels):\n",
    "        self.labels = labels\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        syscall = list(self.dataset.iloc[index].values)\n",
    "        syscall2 = self.dataset.iloc[index][1:]\n",
    "        X = torch.tensor(np.int64(syscall2))\n",
    "        y = self.labels.iloc[index]\n",
    "        return X, y, syscall\n",
    "\n",
    "    \n",
    "# Data generator and loader\n",
    "batch_size = 32\n",
    "\n",
    "training_set = Dataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                           batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "validation_set = Dataset(X_val, y_val)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_set, \n",
    "                                           batch_size=batch_size,\n",
    "                                               shuffle=False)\n",
    "\n",
    "test_set = TestDataset(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = df.shape[1]-2\n",
    "hidden_size = 400\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x.float())\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch [1/5], Step [960/960], Loss: 0.0368\n",
      "Epoch [2/5], Step [960/960], Loss: 0.0211\n",
      "Epoch [3/5], Step [960/960], Loss: 0.1191\n",
      "Epoch [4/5], Step [960/960], Loss: 0.0033\n",
      "Epoch [5/5], Step [960/960], Loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "print(\"Training\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (batch_data, batch_labels) in enumerate(train_loader):\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % total_step == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Accuracy of the network on the 4475 validation data: 98.52513966480447 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation\")\n",
    "with torch.set_grad_enabled(False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_data, batch_labels in validation_loader:\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "        outputs = model(batch_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the {} validation data: {} %'.format(X_val.shape[0],\n",
    "                                                                           100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Accuracy of the network on the 8688 testing data: 98.51519337016575 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "tofile = []\n",
    "y_pred = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_data, batch_labels, syscall in test_loader:\n",
    "\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "        outputs = model(batch_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred += list(predicted)\n",
    "        total += batch_labels.size(0)\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] == batch_labels[i]:\n",
    "                correct += 1\n",
    "                tofile.append((syscall[0][i], predicted[i].item(), batch_labels[i].item()))\n",
    "                \n",
    "    print('Accuracy of the network on the {} testing data: {} %'.format(X_test.shape[0],\n",
    "                                                                        100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using F1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true=y_test,\n",
    "                                                           y_pred=y_pred,\n",
    "                                                          average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is:  0.9103057889822597\n"
     ]
    }
   ],
   "source": [
    "print(\"precision is: \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall is:  0.7380550653994021\n"
     ]
    }
   ],
   "source": [
    "print(\"recall is: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is:  0.8001677108327183\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"classification.txt\", \"w\")\n",
    "for hash_str, prediction, actual in tofile:\n",
    "\n",
    "    f.write(str(hash_str)+ \"\\t\"+ str(prediction) + \"\\t\"+ str(actual)+ \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
